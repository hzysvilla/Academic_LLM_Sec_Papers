# Academic Papers About LLM Application on Cyber Security.

A curated LLM Security Application related academic papers. All papers are sorted based on the conference name and published year.

**üí° Welcome developers or researchers to add more published papers to this list**.

Welcome to visit my [homepage](https://hzysvilla.github.io/) and [Google Scholar](https://scholar.google.com/citations?user=O_vixKoAAAAJ).

üì¨ The cryptocurrency donation address: 0xCC28B05fE858CDbc8692E3272A4451111bDCf700.

## Listed Conferences
|    üîê Security & Crypto               |              üåê Networking & Database               |üíª  Software Engineering & Programming Language | üß†  Machine Learning    |
| :---------------------------------: | :-----------------------------------------------: | :-----------------------------------------: | :------------------: |
|           [IEEE S&P](#sp)           |             [SIGMETRICS](#sigmetrics)             |                [ICSE](#icse)                |     [AAAI](#aaai)    |
|           [ACM CCS](#ccs)           |                   [ICDE](#others)                 |            [ESEC/FSE](#esecfse)             |     [ACL](#acl)      |
| [USENIX Security](#usenix-security) |                   [VLDB](#others)                 |                 [ASE](#ase)                 |     [ICML](#ICML)    |
|           [NDSS](#ndss)             |               [ACM SIGMOD](#others)               |              [ACM PLDI](#pldi)              |  [NeurIPS](#neurips) |
|        [IEEE DSN](#dsn)             |             [IEEE INFOCOM](#infocom)              |            [ACM OOPSLA](#oopsla)            |                      |
|         [SRCS](#others)             |                   [IMC](#imc)                     |              [ISSTA](#issta)                |                      |
|          [RAID](#raid)              |                   [WWW](#www)                     |             [ACM POPL](#popl)               |                      |
|          [CAV](#cav)                |                                                   |                                             |                      |

## Listed Journals
- [TOSEM](#tosem)
- [TSE](#tse)
- [TDSC](#tdsc)
- [TIFS](#tifs)

### Also including:
* [Survey](#Literature-Review), [ACL](#miscellaneous).

-----

# Literature Review

### 2025

* [Recent Advances in Large Language Model Benchmarks Against Data Contamination: From Static to Dynamic Evaluation](https://arxiv.org/pdf/2502.17521)
* [ADVANCES AND CHALLENGES IN FOUNDATION AGENTS FROM BRAIN-INSPIRED INTELLIGENCE TO EVOLUTIONARY, COLLABORATIVE, AND SAFE SYSTEMS](https://arxiv.org/pdf/2504.01990)
* [Foundation Models Defining a New Era in Vision: A Survey and Outlook](https://ieeexplore.ieee.org/abstract/document/10834497)

### 2024

* [Large Language Models for Blockchain Security: A Systematic Literature Review](https://eprint.iacr.org/2024/477.pdf).
* [A survey on large language model (llm) security and privacy: The good, the bad, and the ugly](https://arxiv.org/pdf/2403.14280).
* [Large language models for software engineering: A systematic literature review](https://arxiv.org/pdf/2308.10620).
* [Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices](https://arxiv.org/pdf/2403.12503).
* [Unveiling security, privacy, and ethical concerns of chatgpt](https://arxiv.org/abs/2307.14192).
* [Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond](https://dl.acm.org/doi/pdf/10.1145/3649506)

-----

# Conference

## S&P

### 2025

* [Prompt Inversion Attack against Collaborative Inference of Large Language Models](https://arxiv.org/pdf/2503.09022)
* [Supporting Human Raters with the Detection of Harmful Content using Large Language Models](https://arxiv.org/pdf/2406.12800)
* [BAIT: Large Language Model Backdoor Scanning by Inverting Attack Target](https://www.cs.purdue.edu/homes/an93/static/papers/SP25_Shen.pdf)
* [SV-TrustEval-C: Evaluating Structure and Semantic Reasoning in Large Language Models for Source Code Vulnerability Analysis](https://arxiv.org/pdf/2505.20630)
* [CODEBREAKER: Dynamic Extraction Attacks on Code Language Models](https://www.computer.org/csdl/proceedings-article/sp/2025/223600a522/26hiTLYepe8)
* [Fuzz-Testing Meets LLM-Based Agents: An Automated and Efficient Framework for Jailbreaking Text-To-Image Generation Models](https://www.computer.org/csdl/proceedings-article/sp/2025/223600a336/26hiTETXKow)
* [Modifier Unlocked: Jailbreaking Text-to-Image Models Through Prompts](https://www.computer.org/csdl/proceedings-article/sp/2025/223600a355/26EkESqqGlO)

### 2024

* [On Large Language Models‚Äô Resilience to Coercive Interrogation](https://www.cs.purdue.edu/homes/cheng535/static/papers/sp24_lint.pdf).
* [Combing for Credentials: Active Pattern Extraction from Smart Reply](https://arxiv.org/pdf/2207.10802).
* [DrSec: Flexible Distributed Representations for Efficient Endpoint Security](https://users.cs.duke.edu/~mlentz/papers/drsec_sp24.pdf).
* [Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in LargeLanguage Models](https://arxiv.org/pdf/2312.15099).
* [Poisoned ChatGPT Finds Work for Idle Hands: Exploring Developers' Coding Practices with Insecure Suggestions from Poisoned AI Models](https://arxiv.org/pdf/2312.06227).
* [TROJANPUZZLE: Covertly Poisoning Code-Suggestion Models](https://arxiv.org/pdf/2301.02344).
* [Transferable Multimoda!Attack on Vision-LanguagePre-Training Models](https://ieeexplore.ieee.org/abstract/document/10646738).
* [You Only Prompt Once: On the Capabilities of PromptLearning on Large LanguageModels to Tackle ToxicContent](https://arxiv.org/pdf/2308.05596).
* [SMARTINV: Multimodal Learning for Smart Contract Invariant Inference](https://arxiv.org/pdf/2411.09217).
* [LLMIF: Augmented Large Language Model for Fuzzing IoT Devices](https://www.jcwang.me/llmif.pdf).

### 2023

* [Examining zero-shot vulnerability repair with large language models](https://arxiv.org/pdf/2112.02125).
* [Analyzing Leakage of Personally Identifiable Information in Language Models](https://arxiv.org/pdf/2302.00539).

### 2022

* [Asleep at the Keyboard? Assessing the Security of GitHub Copilot's Code Contributions](https://arxiv.org/pdf/2108.09293).
* [Spinning language models: Risks of propaganda-as-a-service and countermeasures](https://arxiv.org/pdf/2112.05224).

### 2020

* [Privacy risks of general-purpose language models](https://secsys.fudan.edu.cn/_upload/article/files/83/cf/30cf2162490d965e57d40c5690df/33a28df5-f9d1-45d3-bfa1-971de54513b3.pdf)

---

## CCS

### 2025

* [GenderCARE: A comprehensive framework for assessing and reducing gender bias in large language models](https://dl.acm.org/doi/pdf/10.1145/3658644.3670284)
* ["Better Be Computer or I'm Dumb": A Large-Scale Evaluation of Humans as Audio Deepfake Detectors](https://cise.ufl.edu/~butler/pubs/ccs24-warren-deepfake.pdf)
* [zkLLM: Zero Knowledge Proofs for Large Language Models](https://arxiv.org/pdf/2404.16109)
* [PLeak: Prompt Leaking Attacks against Large Language Model Applications](https://arxiv.org/abs/2405.06823)
* ["Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models](https://arxiv.org/pdf/2308.03825)
* [A Causal Explainable Guardrails for Large Language Models](https://arxiv.org/pdf/2405.04160)
* [ProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations with Only Documentation via Large Language Model](https://arxiv.org/pdf/2409.00922)
* [Unveiling the Vulnerability of Private Fine-Tuning in Split-Based Frameworks for Large Language Models: A Bidirectionally Enhanced Attack](https://arxiv.org/pdf/2409.00960)
* [PromSec: Prompt Optimization for Secure Generation of Functional Source Code with Large Language Models](https://dl.acm.org/doi/pdf/10.1145/3658644.3690298)
* [Legilimens: Practical and Unified Content Moderation for Large Language Model Services](https://arxiv.org/pdf/2408.15488)
* [The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks](https://dl.acm.org/doi/pdf/10.1145/3658644.3690325)

### 2024

* [PromptFuzz: Prompt Fuzzing for Fuzz Driver Generation]().
* [GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models](https://zjzac.github.io/publications/pdf/CCS_24_bias.pdf).

### 2023

* [Stealing the Decoding Algorithms of Language Models](https://arxiv.org/abs/2303.04729).
* [Large Language Models for Code: Security Hardening and Adversarial Testing](https://arxiv.org/pdf/2302.05319).
* [Not What You've Signed Up For: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection](https://arxiv.org/abs/2302.12173).
* [Protecting intellectual property of large language model-based code generation apis via watermarks](https://dl.acm.org/doi/pdf/10.1145/3576915.3623120).
* [Dp-forward: Fine-tuning and inference on language models with differential privacy in forward pass](https://arxiv.org/abs/2309.06746).

---

## USENIX Security

### 2025

* [Am I Infected? Lessons from Operating a Large-Scale IoT Security Diagnostic Service](https://arxiv.org/pdf/2501.07326)
* [PoisonedRAG: Knowledge Corruption Attacks to Retrieval-Augmented Generation of Large Language Models](https://arxiv.org/pdf/2402.07867)
* [JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and Manipulation](https://arxiv.org/pdf/2502.07557)
* [LLMmap: Fingerprinting for Large Language Models](https://arxiv.org/pdf/2407.15847?)
* [Generated Data with Fake Privacy: Hidden Dangers of Fine-tuning Large Language Models on Generated Data](https://arxiv.org/pdf/2409.11423)
* [Towards Label-Only Membership Inference Attack against Pre-trained Large Language Models](https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-1107-he.pdf)
* [APPATCH: Automated Adaptive Prompting Large Language Models for Real-World Software Vulnerability Patching](https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-1174-nong.pdf)
* [Mirage in the Eyes: Hallucination Attack on Multi-modal Large Language Models with Only Attention Sink](https://arxiv.org/pdf/2501.15269)
* [StruQ: Defending Against Prompt Injection with Structured Queries](https://arxiv.org/pdf/2402.06363)
* [On the Proactive Generation of Unsafe Images From Text-To-Image Models Using Benign Prompts](https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-590-wu-yixin-generation.pdf)

### 2024

* [Rapid Adoption, Hidden Risks: The Dual Impact of Large Language Model Customization](https://arxiv.org/pdf/2402.09179v3).
* [PENTESTGPT: An LLM-empowered Automatic Penetration Testing Tool](https://arxiv.org/pdf/2308.06782)
* [Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models](https://www.usenix.org/conference/usenixsecurity24/presentation/yu-zhiyuan).
* [EaTVul: ChatGPT-based Evasion Attack Against Software Vulnerability Detection](https://arxiv.org/abs/2407.19216).
* [Fuzzing BusyBox: Leveraging LLM and Crash Reuse for Embedded Bug Unearthing](https://www.usenix.org/conference/usenixsecurity24/presentation/asmita).

### 2023

* [Lost at c: A user study on the security implications of large language model code assistants](https://arxiv.org/abs/2208.09727).
* [CodexLeaks: Privacy Leaks from Code Generation Language Models in GitHub Copilot](https://www.usenix.org/system/files/usenixsecurity23-niu.pdf).
* [{Two-in-One}: A Model Hijacking Attack Against Text Generation Models](https://www.usenix.org/system/files/usenixsecurity23-si.pdf).

### 2021

* [Extracting Training Data from Large Language Models](https://www.usenix.org/system/files/sec21-carlini-extracting.pdf).
* [You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion](https://www.usenix.org/system/files/sec21-schuster.pdf).

---

## NDSS

### 2025

* [BumbleBee: Secure Two-party Inference Framework for Large Transformers](https://www.ndss-symposium.org/ndss-paper/bumblebee-secure-two-party-inference-framework-for-large-transformers/)
* [The Philosopher‚Äôs Stone: Trojaning Plugins of Large Language Models](https://www.ndss-symposium.org/ndss-paper/the-philosophers-stone-trojaning-plugins-of-large-language-models/)
* [The Skeleton Keys: A Large Scale Analysis of Credential Leakage in Mini-apps](https://www.ndss-symposium.org/ndss-paper/the-skeleton-keys-a-large-scale-analysis-of-credential-leakage-in-mini-apps/)
* [Safety Misalignment Against Large Language Models](https://www.ndss-symposium.org/ndss-paper/safety-misalignment-against-large-language-models/)
* [The (Un)usual Suspects ‚Äì Studying Reasons for Lacking Updates in WordPress](https://www.ndss-symposium.org/ndss-paper/the-unusual-suspects-studying-reasons-for-lacking-updates-in-wordpress/)
* [CLIBE: Detecting Dynamic Backdoors in Transformer-based NLP Models](https://www.ndss-symposium.org/ndss-paper/clibe-detecting-dynamic-backdoors-in-transformer-based-nlp-models/)
* [Secure Transformer Inference Made Non-interactive](https://www.ndss-symposium.org/ndss-paper/secure-transformer-inference-made-non-interactive/)
* [Transparency or Information Overload? Evaluating Users‚Äô Comprehension and Perceptions of the iOS App Privacy Report](https://www.ndss-symposium.org/ndss-paper/transparency-or-information-overload-evaluating-users-comprehension-and-perceptions-of-the-ios-app-privacy-report/)
* [Provably Unlearnable Data Examples](https://www.ndss-symposium.org/ndss-paper/provably-unlearnable-data-examples/)

### 2024

* [LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors](https://www.ndss-symposium.org/wp-content/uploads/2024-238-paper.pdf)
* [Analysis of the Effect of the Difference between Japanese and English Input on ChatGPT-Generated Secure Codes](https://www.ndss-symposium.org/wp-content/uploads/madweb2024-84-paper.pdf).
* [MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots](https://www.ndss-symposium.org/ndss-paper/masterkey-automated-jailbreaking-of-large-language-model-chatbots/).
* [DeGPT: Optimizing Decompiler Output with LLM](https://www.ndss-symposium.org/wp-content/uploads/2024-401-paper.pdf).
* [DEMASQ: Unmasking the ChatGPT Wordsmith](https://arxiv.org/abs/2311.05019).
* [Large Language Model guided Protocol Fuzzing](https://abhikrc.com/pdf/NDSS24.pdf).
* [Facilitating Threat Modeling by Leveraging Large Language Models](https://www.ndss-symposium.org/wp-content/uploads/aiscc2024-16-paper.pdf)

---

## OOPSLA

### 2024

* [Enhancing Static Analysis for Practical Bug Detection: An LLM-Integrated Approach](https://www.cs.ucr.edu/~zhiyunq/pub/oospla24_llift.pdf).
* [PyDex: Repairing Bugs in Introductory Python Assignments using LLMs](https://arxiv.org/pdf/2209.14876).

---

## ICSE

### 2026

* [Unseen Horizons: Unveiling the Real Capability of LLM Code Generation Beyond the Familiar]().
* 

### 2024

* [Large Language Models are Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT](https://arxiv.org/pdf/2304.02014)
* [Fuzz4All: Universal Fuzzing with Large Language Models](https://arxiv.org/pdf/2308.04748).
* [LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing](https://petertsehsun.github.io/papers/LLMParser.pdf).
* [Exploring the Potential of ChatGPT in Automated Code Refinement: An Empirical Study](https://arxiv.org/pdf/2309.08221).
* [Large Language Models are  Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT](https://arxiv.org/pdf/2304.02014).
* [UniLog: Automatic Logging via LLM and In-Context Learning](https://dl.acm.org/doi/pdf/10.1145/3597503.3623326).
* [Prompting Is All You Need: Automated Android Bug Replay with Large Language Models](https://arxiv.org/pdf/2306.01987).
* [Large Language Models for Test-Free Fault Localization](https://arxiv.org/pdf/2310.01726).
* [Large language models are few-shot testers: Exploring llm-based general bug reproduction](https://arxiv.org/abs/2209.11515).
* [Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning](https://arxiv.org/pdf/2304.11384).
* [Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries]().
* [GPTScan: Detecting Logic Vulnerabilities in Smart Contracts by Combining GPT with Program Analysis](https://arxiv.org/pdf/2308.03314).
* [Automated Program Repair in the Era of Large Pre-trained Language Models](https://lingming.cs.illinois.edu/publications/icse2023a.pdf).

### 2023

* [Does data sampling improve deep learning-based vulnerability detection? Yeas! and Nays!]().
* [An Empirical Study of Deep Learning Models for Vulnerability Detection](https://arxiv.org/pdf/2212.08109).
* [RepresentThemAll: A Universal Learning Representation of Bug Reports]().
* [Contrabert: Enhancing code pre-trained models via contrastive learning](https://arxiv.org/pdf/2301.09072).
* [On the robustness of code generation techniques: An empirical study on github copilot](https://sscalabrino.github.io/files/2023/ICSE2023OnTheRobustness.pdf).
* [Two sides of the same coin: Exploiting the impact of identifiers in neural code comprehension](https://yuyue.github.io/res/paper/NeuralCode-ICSE2023.pdf).
* [Automated repair of programs from large language models](https://arxiv.org/pdf/2205.10583).
* [Cctest: Testing and repairing code completion systems](https://arxiv.org/pdf/2208.08289).
* [CodaMosa: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models]().
* [Impact of Code Language Models on Automated Program Repair](https://arxiv.org/pdf/2302.05020).

### 2022

* [ReCode: Robustness Evaluation of Code Generation Models](https://aclanthology.org/2023.acl-long.773.pdf).

---

## CAV

### 2024

* [Enchanting Program Specification Synthesis by Large Language Models using Static Analysis and Program Verification](https://arxiv.org/abs/2404.00762).

---

## ASE

### 2024

* [Better Patching Using LLM Prompting, via Self-Consistency](https://arxiv.org/pdf/2306.00108).
* [Towards Autonomous Testing Agents via Conversational Large Language Models](https://arxiv.org/pdf/2306.05152).
* [Let's Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph through AI Chain](https://arxiv.org/abs/2309.16134).
* [Log Parsing: How Far Can ChatGPT Go?](https://arxiv.org/pdf/2306.01590).

### 2022

* [Robust Learning of Deep Predictive Models from Noisy and Imbalanced Software Engineering Datasets]().

---

## ISSTA

### 2024

* [Large Language Models Are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models](https://arxiv.org/pdf/2212.14834).

### 2023

* [How Effective Are Neural Networks for Fixing Security Vulnerabilities](https://arxiv.org/abs/2305.18607).

---

## ESEC/FSE

### 2023

* [InferFix: End-to-End Program Repair with LLMs](https://arxiv.org/pdf/2303.07263).
* [Getting pwn'd by ai: Penetration testing with large language models](https://arxiv.org/abs/2308.00121).
* [Llm-based code generation method for golang compiler testing]().
* [Assisting static analysis with large language models: A chatgpt experiment](https://sp2023.ieee-security.org/downloads/SP23-posters/sp23-posters-paper39-final_version_2_page_abstract.pdf).
* [Assess and Summarize: Improve Outage Understanding with Large Language Models](https://arxiv.org/abs/2305.18084).

### 2022

* [Generating realistic vulnerabilities via neural code editing: an empirical study](https://chapering.github.io/pubs/fse22yu.pdf).
* [You see what I want you to see: poisoning vulnerabilities in neural code search](https://arxiv.org/pdf/2007.02220).

### 2021

* [Vulnerability detection with fine-grained interpretations](https://arxiv.org/abs/2106.10478).

---

## ACL

### 2024

* [Not the end of story: An evaluation of chatgpt-driven vulnerability description mappings]().
* [Understanding Programs by Exploiting (Fuzzing) Test Cases]().

### 2023

* [Backdooring Neural Code Search]().
* [Membership inference attacks against language models via neighbourhood comparison](https://proceedings.mlr.press/v202/yu23c/yu23c.pdf).
* [Are you copying my model? protecting the copyright of large language models for eaas via backdoor watermark](https://arxiv.org/pdf/2305.10036).

### 2022

* [ReCode: Robustness Evaluation of Code Generation Models]().
* [Knowledge unlearning for mitigating privacy risks in language models](https://arxiv.org/pdf/2210.01504).

### 2018

* [Contamination attacks and mitigation in multi-party machine learning]().

---

## AAAI

### 2022

* [Adversarial Robustness of Deep Code Comment Generation](https://dl.acm.org/doi/abs/10.1145/3501256).

---

## ICML

### 2025

### 2024

1.* [Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression](https://arxiv.org/pdf/2403.15447)

### 2023

1.* [Bag of tricks for training data extraction from language models](https://arxiv.org/pdf/2302.04460).

### 2022

1.* [Deduplicating training data mitigates privacy risks in language models](https://proceedings.mlr.press/v162/kandpal22a/kandpal22a.pdf).

---

## NeurIPS

### 2025

### 2024

### 2022

* [Recovering private text in federated learning of language models](https://proceedings.neurips.cc/paper_files/paper/2022/file/35b5c175e139bff5f22a5361270fce87-Paper-Conference.pdf).

---


## WWW

### 2025

* [SuiGPT MAD: Move AI Decompiler to Improve Transparency and Auditability on Non-Open-Source Blockchain Smart Contract]().

### 2024

* [ZipZap: Efficient Training of Language Models for Large-Scale Fraud Detection on Blockchain]().

### 2022

* [Coprotector: Protect open-source code against unauthorized training usage with data poisoning]().


-----

# journal

## TIFS

* [(Security) Assertions by Large Language Models]().
* [A Performance-Sensitive Malware Detection System Using Deep Learning on Mobile Devices]()* [A Performance-Sensitive Malware Detection System Using Deep Learning on Mobile Devices]().

## TDSC

* [PrivacyAsst: Safeguarding User Privacy in Tool-Using Large Language Model Agents]().
* [CD-VulD: Cross-Domain Vulnerability Discovery Based on Deep Domain Adaptation]().

## TSE

* [Software Testing with Large Language Models: Survey, Landscape, and Vision]().
* [An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation]().
* [Deep Learning Based Vulnerability Detection: Are We There Yet?]().
* [On the Value of Oversampling for Deep Learning in Software Defect Prediction]().

## TOSEM

* [Prompt Sapper: A LLM-Empowered Production Tool for Building AI Chains]().
* [Adversarial Robustness of Deep Code Comment Generation ]().

## Miscellaneous

* [LLM4Fuzz: Guided Fuzzing of Smart Contracts with Large Language Models](https://arxiv.org/pdf/2401.11108)
* [CHEMFUZZ: Large Language Models-assisted Fuzzing for  Quantum Chemistry Software  Bug Detection]()
* [Attack Prompt Generation for Red Teaming and Defending Large Language Models]()

