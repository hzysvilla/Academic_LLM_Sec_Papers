# Academic Papers About LLM Application on Cyber Security.

A curated LLM Security Application related academic papers. All papers are sorted based on the conference name and published year.

**Welcome developers or researchers to add more published papers to this list**.

The cryptocurrency donation address: 0xCC28B05fE858CDbc8692E3272A4451111bDCf700.

Welcome to visit my [homepage](https://hzysvilla.github.io/) and [Google Scholar](https://scholar.google.com/citations?user=O_vixKoAAAAJ).

## Table of Listed Conferences
|     Security & Crypto               |               Networking & Database               | Software Engineering & Programming Language |  Machine Learning    |
| :---------------------------------: | :-----------------------------------------------: | :-----------------------------------------: | :------------------: |
|           [IEEE S&P](#sp)           |             [SIGMETRICS](#sigmetrics)             |                [ICSE](#icse)                |     [AAAI](#aaai)    |
|           [ACM CCS](#ccs)           |                   [ICDE](#others)                 |            [ESEC/FSE](#esecfse)             |     [ACL](#acl)      |
| [USENIX Security](#usenix-security) |                   [VLDB](#others)                 |                 [ASE](#ase)                 |     [ICML](#ICML)    |
|           [NDSS](#ndss)             |               [ACM SIGMOD](#others)               |              [ACM PLDI](#pldi)              |  [NeurIPS](#neurips) |
|        [IEEE DSN](#dsn)             |             [IEEE INFOCOM](#infocom)              |            [ACM OOPSLA](#oopsla)            |                      |
|         [SRCS](#others)             |                   [IMC](#imc)                     |              [ISSTA](#issta)                |                      |
|          [RAID](#raid)              |                   [WWW](#www)                     |             [ACM POPL](#popl)               |                      |
|          [CAV](#cav)                |                                                   |                                             |                      |

## Table of Listed Journals
- [TOSEM](#tosem)
- [TSE](#tse)
- [TDSC](#tdsc)
- [TIFS](#tifs)

### Also including:
* [Survey](#Literature-Review), [ACL](#miscellaneous).

-----

# Literature Review

### 2024

[Large Language Models for Blockchain Security: A Systematic Literature Review](https://eprint.iacr.org/2024/477.pdf).

[A survey on large language model (llm) security and privacy: The good, the bad, and the ugly](https://arxiv.org/pdf/2403.14280).

[Large language models for software engineering: A systematic literature review](https://arxiv.org/pdf/2308.10620).

[Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices](https://arxiv.org/pdf/2403.12503).

[Unveiling security, privacy, and ethical concerns of chatgpt](https://arxiv.org/abs/2307.14192).

-----

# Conference

## S&P

### 2024

[Combing for Credentials: Active Pattern Extraction from Smart Reply]().

[DrSec: Flexible Distributed Representations for Efficient Endpoint Security]().

[Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in LargeLanguage Models]().

[Poisoned ChatGPT Finds Work for Idle Hands: Exploring Developers' Coding Practices with Insecure Suggestions from Poisoned AI Models]().

[TROJANPUZZLE: Covertly Poisoning Code-Suggestion Models]().

[Transferable Multimoda!Attack on Vision-LanguagePre-Training Models]().

[You Only Prompt Once: On the Capabilities of PromptLearning on Large LanguageModels to Tackle ToxicContent]().

[SMARTINV: Multimodal Learning for Smart Contract Invariant Inference]().

[LLMIF: Augmented Large Language Model for Fuzzing IoT Devices]().

### 2023

[Examining zero-shot vulnerability repair with large language models](https://arxiv.org/pdf/2112.02125).

[Analyzing Leakage of Personally Identifiable Information in Language Models](https://arxiv.org/pdf/2302.00539).

### 2022

[Asleep at the Keyboard? Assessing the Security of GitHub Copilot's Code Contributions](https://arxiv.org/pdf/2108.09293).

[Spinning language models: Risks of propaganda-as-a-service and countermeasures](https://arxiv.org/pdf/2112.05224).

### 2020

[Privacy risks of general-purpose language models](https://secsys.fudan.edu.cn/_upload/article/files/83/cf/30cf2162490d965e57d40c5690df/33a28df5-f9d1-45d3-bfa1-971de54513b3.pdf)

---

## CCS

### 2024

[GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models](https://zjzac.github.io/publications/pdf/CCS_24_bias.pdf).


### 2023

[Stealing the Decoding Algorithms of Language Models](https://arxiv.org/abs/2303.04729).

[Large Language Models for Code: Security Hardening and Adversarial Testing](https://arxiv.org/pdf/2302.05319).

[Not What You've Signed Up For: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection](https://arxiv.org/abs/2302.12173).

[Protecting intellectual property of large language model-based code generation apis via watermarks](https://dl.acm.org/doi/pdf/10.1145/3576915.3623120).

[Dp-forward: Fine-tuning and inference on language models with differential privacy in forward pass](https://arxiv.org/abs/2309.06746).

---

## USENIX Security

### 2024

[Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models](https://www.usenix.org/conference/usenixsecurity24/presentation/yu-zhiyuan).

[Large Language Models for Code Analysis: Do LLMs Really Do Their Job?]().

[EaTVul: ChatGPT-based Evasion Attack Against Software Vulnerability Detection]().

### 2023

[Lost at c: A user study on the security implications of large language model code assistants](https://arxiv.org/abs/2208.09727).

[CodexLeaks: Privacy Leaks from Code Generation Language Models in GitHub Copilot](https://www.usenix.org/system/files/usenixsecurity23-niu.pdf).

[{Two-in-One}: A Model Hijacking Attack Against Text Generation Models](https://www.usenix.org/system/files/usenixsecurity23-si.pdf).

### 2021

[Extracting Training Data from Large Language Models](https://www.usenix.org/system/files/sec21-carlini-extracting.pdf).

[You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion](https://www.usenix.org/system/files/sec21-schuster.pdf).

---

## NDSS

### 2024

[LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors](https://www.ndss-symposium.org/wp-content/uploads/2024-238-paper.pdf)

[Analysis of the Effect of the Difference between Japanese and English Input on ChatGPT-Generated Secure Codes](https://www.ndss-symposium.org/wp-content/uploads/madweb2024-84-paper.pdf).

[MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots](https://www.ndss-symposium.org/ndss-paper/masterkey-automated-jailbreaking-of-large-language-model-chatbots/).

[DeGPT: Optimizing Decompiler Output with LLM](https://www.ndss-symposium.org/wp-content/uploads/2024-401-paper.pdf).

[DEMASQ: Unmasking the ChatGPT Wordsmith](https://arxiv.org/abs/2311.05019).

[Large Language Model guided Protocol Fuzzing](https://abhikrc.com/pdf/NDSS24.pdf).

[Facilitating Threat Modeling by Leveraging Large Language Models](https://www.ndss-symposium.org/wp-content/uploads/aiscc2024-16-paper.pdf)

---

## OOPSLA

### 2024

[Enhancing Static Analysis for Practical Bug Detection: An LLM-Integrated Approach](https://www.cs.ucr.edu/~zhiyunq/pub/oospla24_llift.pdf).

[PyDex: Repairing Bugs in Introductory Python Assignments using LLMs](https://arxiv.org/pdf/2209.14876).

---

## ICSE

### 2024

[Large Language Models are Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT](https://arxiv.org/pdf/2304.02014)

[Fuzz4All: Universal Fuzzing with Large Language Models](https://arxiv.org/pdf/2308.04748).

[LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing](https://petertsehsun.github.io/papers/LLMParser.pdf).

[Exploring the Potential of ChatGPT in Automated Code Refinement: An Empirical Study](https://arxiv.org/pdf/2309.08221).

[Large Language Models are  Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT](https://arxiv.org/pdf/2304.02014).

[UniLog: Automatic Logging via LLM and In-Context Learning](https://dl.acm.org/doi/pdf/10.1145/3597503.3623326).

[Prompting Is All You Need: Automated Android Bug Replay with Large Language Models](https://arxiv.org/pdf/2306.01987).

[Large Language Models for Test-Free Fault Localization](https://arxiv.org/pdf/2310.01726).

[Large language models are few-shot testers: Exploring llm-based general bug reproduction](https://arxiv.org/abs/2209.11515).

[Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning](https://arxiv.org/pdf/2304.11384).

[Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries]().

[GPTScan: Detecting Logic Vulnerabilities in Smart Contracts by Combining GPT with Program Analysis](https://arxiv.org/pdf/2308.03314).

[Automated Program Repair in the Era of Large Pre-trained Language Models](https://lingming.cs.illinois.edu/publications/icse2023a.pdf).

### 2023

[Does data sampling improve deep learning-based vulnerability detection? Yeas! and Nays!]().

[An Empirical Study of Deep Learning Models for Vulnerability Detection](https://arxiv.org/pdf/2212.08109).

[RepresentThemAll: A Universal Learning Representation of Bug Reports]().

[Contrabert: Enhancing code pre-trained models via contrastive learning](https://arxiv.org/pdf/2301.09072).

[On the robustness of code generation techniques: An empirical study on github copilot](https://sscalabrino.github.io/files/2023/ICSE2023OnTheRobustness.pdf).

[Two sides of the same coin: Exploiting the impact of identifiers in neural code comprehension](https://yuyue.github.io/res/paper/NeuralCode-ICSE2023.pdf).

[Automated repair of programs from large language models](https://arxiv.org/pdf/2205.10583).

[Cctest: Testing and repairing code completion systems](https://arxiv.org/pdf/2208.08289).

[CodaMosa: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models]().

[Impact of Code Language Models on Automated Program Repair](https://arxiv.org/pdf/2302.05020).

### 2022

[ReCode: Robustness Evaluation of Code Generation Models](https://aclanthology.org/2023.acl-long.773.pdf).

---

## CAV

### 2024

[Enchanting Program Specification Synthesis by Large Language Models using Static Analysis and Program Verification](https://arxiv.org/abs/2404.00762).

---

## ASE

### 2024

[Better Patching Using LLM Prompting, via Self-Consistency](https://arxiv.org/pdf/2306.00108).

[Towards Autonomous Testing Agents via Conversational Large Language Models](https://arxiv.org/pdf/2306.05152).

[Let's Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph through AI Chain](https://arxiv.org/abs/2309.16134).

[Log Parsing: How Far Can ChatGPT Go?](https://arxiv.org/pdf/2306.01590).

### 2022

[Robust Learning of Deep Predictive Models from Noisy and Imbalanced Software Engineering Datasets]().

---

## ISSTA

### 2024

[Large Language Models Are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models](https://arxiv.org/pdf/2212.14834).

### 2023

[How Effective Are Neural Networks for Fixing Security Vulnerabilities](https://arxiv.org/abs/2305.18607).

---

## ESEC/FSE

### 2023

[InferFix: End-to-End Program Repair with LLMs](https://arxiv.org/pdf/2303.07263).

[Getting pwn'd by ai: Penetration testing with large language models](https://arxiv.org/abs/2308.00121).

[Llm-based code generation method for golang compiler testing]().

[Assisting static analysis with large language models: A chatgpt experiment](https://sp2023.ieee-security.org/downloads/SP23-posters/sp23-posters-paper39-final_version_2_page_abstract.pdf).

[Assess and Summarize: Improve Outage Understanding with Large Language Models](https://arxiv.org/abs/2305.18084).

### 2022

[Generating realistic vulnerabilities via neural code editing: an empirical study](https://chapering.github.io/pubs/fse22yu.pdf).

[You see what I want you to see: poisoning vulnerabilities in neural code search](https://arxiv.org/pdf/2007.02220).

### 2021

[Vulnerability detection with fine-grained interpretations](https://arxiv.org/abs/2106.10478).

---

## ACL

### 2024

[Not the end of story: An evaluation of chatgpt-driven vulnerability description mappings]().

[Understanding Programs by Exploiting (Fuzzing) Test Cases]().

### 2023

[Backdooring Neural Code Search]().

[Membership inference attacks against language models via neighbourhood comparison](https://proceedings.mlr.press/v202/yu23c/yu23c.pdf).

[Are you copying my model? protecting the copyright of large language models for eaas via backdoor watermark](https://arxiv.org/pdf/2305.10036).

### 2022

[ReCode: Robustness Evaluation of Code Generation Models]().

[Knowledge unlearning for mitigating privacy risks in language models](https://arxiv.org/pdf/2210.01504).

### 2018

[Contamination attacks and mitigation in multi-party machine learning]().

---

## AAAI

### 2022

[Adversarial Robustness of Deep Code Comment Generation]().

---

## ICML

### 2023

[Bag of tricks for training data extraction from language models](https://arxiv.org/pdf/2302.04460).

### 2022

[Deduplicating training data mitigates privacy risks in language models](https://proceedings.mlr.press/v162/kandpal22a/kandpal22a.pdf).

---

## NeurIPS

### 2022

[Recovering private text in federated learning of language models](https://proceedings.neurips.cc/paper_files/paper/2022/file/35b5c175e139bff5f22a5361270fce87-Paper-Conference.pdf).

---


## WWW

### 2024

[ZipZap: Efficient Training of Language Models for Large-Scale Fraud Detection on Blockchain]().

### 2022

[Coprotector: Protect open-source code against unauthorized training usage with data poisoning]().


-----

# journal

## TIFS

[(Security) Assertions by Large Language Models]().

[A Performance-Sensitive Malware Detection System Using Deep Learning on Mobile Devices]()[A Performance-Sensitive Malware Detection System Using Deep Learning on Mobile Devices]().

## TDSC

[PrivacyAsst: Safeguarding User Privacy in Tool-Using Large Language Model Agents]().

[CD-VulD: Cross-Domain Vulnerability Discovery Based on Deep Domain Adaptation]().

## TSE

[Software Testing with Large Language Models: Survey, Landscape, and Vision]().

[An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation]().

[Deep Learning Based Vulnerability Detection: Are We There Yet?]().

[On the Value of Oversampling for Deep Learning in Software Defect Prediction]().

## TOSEM

[Prompt Sapper: A LLM-Empowered Production Tool for Building AI Chains]().

[Adversarial Robustness of Deep Code Comment Generation ]().

## Miscellaneous

[LLM4Fuzz: Guided Fuzzing of Smart Contracts with Large Language Models](https://arxiv.org/pdf/2401.11108)

[CHEMFUZZ: Large Language Models-assisted Fuzzing for  Quantum Chemistry Software  Bug Detection]()

[Attack Prompt Generation for Red Teaming and Defending Large Language Models]()

